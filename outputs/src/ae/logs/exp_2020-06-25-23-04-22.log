Config values:
{'name': 'TEST_get_as_onehot', 'model': 'Autoencoder', 'kernel_len': 3, 'latent_len': 6, 'seq_len': 40, 'seq_per_batch': 20, 'input_path': 'data/ref_genome/chr22_excerpt_4m.fa', 'split_prop': 0.05, 'epochs': 2, 'learn_rate': 0.1, 'input_dropout_freq': 0.0, 'latent_noise_std': 0.2, 'save_model': True, 'disable_eval': True, 'neighbour_loss_prop': 0.0, 'load_prev_model_state': None, 'hidden_len': 1, 'pool_size': 1, 'n_conv_and_pool': 1, 'n_conv_before_pool': 1, 'n_linear': 1, 'use_cuda_if_available': True, 'hidden_dropout_freq': 0.1, 'fixed_random_seed': True, 'n_dataloader_workers': 4, 'checkpoint_interval': 10000, 'output_len': 919, 'TEST_use_old_dataset': False, 'TEST_get_as_onehot': False, 'TEST_get_label': False}
reading sequence from file...
Model specification:
Autoencoder(
  (loss_fn): NeighbourDistanceLoss(
    (bce_loss): BCELoss()
    (mse_loss): MSELoss()
  )
  (encode_layers): ModuleDict(
    (input_dropout): SeqDropout(
      (dropout): Dropout2d(p=0.0, inplace=False)
    )
    (conv0): Conv1d(4, 6, kernel_size=(3,), stride=(1,))
    (relu0): ReLU()
  )
  (decode_layers): ModuleDict(
    (latent_noise): GaussianNoise()
    (conv0): ConvTranspose1d(6, 4, kernel_size=(3,), stride=(1,))
    (softmax): Softmax(dim=1)
  )
)
Loading data...
Split training and validation sets...
Create data loaders...
Training for 2 epochs
Using device:
cuda
Saving model to outputs/src/ae/experiment/TEST_get_as_onehotchr22_excerpt_4mAutoencoder3x6d0.0n0.2l0.0_4at0.1_2-4986.pth
Config values:
{'name': 'TEST_get_as_onehot', 'model': 'Autoencoder', 'kernel_len': 3, 'latent_len': 6, 'seq_len': 40, 'seq_per_batch': 20, 'input_path': 'data/ref_genome/chr22_excerpt_4m.fa', 'split_prop': 0.05, 'epochs': 2, 'learn_rate': 0.1, 'input_dropout_freq': 0.0, 'latent_noise_std': 0.2, 'save_model': True, 'disable_eval': True, 'neighbour_loss_prop': 0.0, 'load_prev_model_state': None, 'hidden_len': 1, 'pool_size': 1, 'n_conv_and_pool': 1, 'n_conv_before_pool': 1, 'n_linear': 1, 'use_cuda_if_available': True, 'hidden_dropout_freq': 0.1, 'fixed_random_seed': True, 'n_dataloader_workers': 4, 'checkpoint_interval': 10000, 'output_len': 919, 'TEST_use_old_dataset': False, 'TEST_get_as_onehot': False, 'TEST_get_label': False}
reading sequence from file...
Model specification:
Autoencoder(
  (loss_fn): NeighbourDistanceLoss(
    (bce_loss): BCELoss()
    (mse_loss): MSELoss()
  )
  (encode_layers): ModuleDict(
    (input_dropout): SeqDropout(
      (dropout): Dropout2d(p=0.0, inplace=False)
    )
    (conv0): Conv1d(4, 6, kernel_size=(3,), stride=(1,))
    (relu0): ReLU()
  )
  (decode_layers): ModuleDict(
    (latent_noise): GaussianNoise()
    (conv0): ConvTranspose1d(6, 4, kernel_size=(3,), stride=(1,))
    (softmax): Softmax(dim=1)
  )
)
Loading data...
Split training and validation sets...
Create data loaders...
Training for 2 epochs
Using device:
cuda
Saving model to outputs/src/ae/experiment/TEST_get_as_onehotchr22_excerpt_4mAutoencoder3x6d0.0n0.2l0.0_4at0.1_2-4986.pth
Config values:
{'name': 'TEST_get_as_onehot', 'model': 'Autoencoder', 'kernel_len': 3, 'latent_len': 6, 'seq_len': 40, 'seq_per_batch': 20, 'input_path': 'data/ref_genome/chr22_excerpt_4m.fa', 'split_prop': 0.05, 'epochs': 2, 'learn_rate': 0.1, 'input_dropout_freq': 0.0, 'latent_noise_std': 0.2, 'save_model': True, 'disable_eval': True, 'neighbour_loss_prop': 0.0, 'load_prev_model_state': None, 'hidden_len': 1, 'pool_size': 1, 'n_conv_and_pool': 1, 'n_conv_before_pool': 1, 'n_linear': 1, 'use_cuda_if_available': True, 'hidden_dropout_freq': 0.1, 'fixed_random_seed': True, 'n_dataloader_workers': 4, 'checkpoint_interval': 10000, 'output_len': 919, 'TEST_use_old_dataset': False, 'TEST_get_as_onehot': False, 'TEST_get_label': False}
reading sequence from file...
Model specification:
Autoencoder(
  (loss_fn): NeighbourDistanceLoss(
    (bce_loss): BCELoss()
    (mse_loss): MSELoss()
  )
  (encode_layers): ModuleDict(
    (input_dropout): SeqDropout(
      (dropout): Dropout2d(p=0.0, inplace=False)
    )
    (conv0): Conv1d(4, 6, kernel_size=(3,), stride=(1,))
    (relu0): ReLU()
  )
  (decode_layers): ModuleDict(
    (latent_noise): GaussianNoise()
    (conv0): ConvTranspose1d(6, 4, kernel_size=(3,), stride=(1,))
    (softmax): Softmax(dim=1)
  )
)
Loading data...
Split training and validation sets...
Create data loaders...
Training for 2 epochs
Using device:
cuda
Saving model to outputs/src/ae/experiment/TEST_get_as_onehotchr22_excerpt_4mAutoencoder3x6d0.0n0.2l0.0_4at0.1_2-4986.pth
Config values:
{'name': 'TEST_get_as_onehot', 'model': 'Autoencoder', 'kernel_len': 3, 'latent_len': 6, 'seq_len': 40, 'seq_per_batch': 20, 'input_path': 'data/ref_genome/chr22_excerpt_4m.fa', 'split_prop': 0.05, 'epochs': 2, 'learn_rate': 0.1, 'input_dropout_freq': 0.0, 'latent_noise_std': 0.2, 'save_model': True, 'disable_eval': True, 'neighbour_loss_prop': 0.0, 'load_prev_model_state': None, 'hidden_len': 1, 'pool_size': 1, 'n_conv_and_pool': 1, 'n_conv_before_pool': 1, 'n_linear': 1, 'use_cuda_if_available': True, 'hidden_dropout_freq': 0.1, 'fixed_random_seed': True, 'n_dataloader_workers': 4, 'checkpoint_interval': 10000, 'output_len': 919, 'TEST_use_old_dataset': False, 'TEST_get_as_onehot': False, 'TEST_get_label': False}
reading sequence from file...
Model specification:
Autoencoder(
  (loss_fn): NeighbourDistanceLoss(
    (bce_loss): BCELoss()
    (mse_loss): MSELoss()
  )
  (encode_layers): ModuleDict(
    (input_dropout): SeqDropout(
      (dropout): Dropout2d(p=0.0, inplace=False)
    )
    (conv0): Conv1d(4, 6, kernel_size=(3,), stride=(1,))
    (relu0): ReLU()
  )
  (decode_layers): ModuleDict(
    (latent_noise): GaussianNoise()
    (conv0): ConvTranspose1d(6, 4, kernel_size=(3,), stride=(1,))
    (softmax): Softmax(dim=1)
  )
)
Loading data...
Split training and validation sets...
Create data loaders...
Training for 2 epochs
Using device:
cuda
Saving model to outputs/src/ae/experiment/TEST_get_as_onehotchr22_excerpt_4mAutoencoder3x6d0.0n0.2l0.0_4at0.1_2-4986.pth
Config values:
{'name': 'TEST_get_as_onehot', 'model': 'Autoencoder', 'kernel_len': 3, 'latent_len': 6, 'seq_len': 40, 'seq_per_batch': 20, 'input_path': 'data/ref_genome/chr22_excerpt_4m.fa', 'split_prop': 0.05, 'epochs': 2, 'learn_rate': 0.1, 'input_dropout_freq': 0.0, 'latent_noise_std': 0.2, 'save_model': True, 'disable_eval': True, 'neighbour_loss_prop': 0.0, 'load_prev_model_state': None, 'hidden_len': 1, 'pool_size': 1, 'n_conv_and_pool': 1, 'n_conv_before_pool': 1, 'n_linear': 1, 'use_cuda_if_available': True, 'hidden_dropout_freq': 0.1, 'fixed_random_seed': True, 'n_dataloader_workers': 4, 'checkpoint_interval': 10000, 'output_len': 919, 'TEST_use_old_dataset': False, 'TEST_get_as_onehot': False, 'TEST_get_label': False}
reading sequence from file...
Model specification:
Autoencoder(
  (loss_fn): NeighbourDistanceLoss(
    (bce_loss): BCELoss()
    (mse_loss): MSELoss()
  )
  (encode_layers): ModuleDict(
    (input_dropout): SeqDropout(
      (dropout): Dropout2d(p=0.0, inplace=False)
    )
    (conv0): Conv1d(4, 6, kernel_size=(3,), stride=(1,))
    (relu0): ReLU()
  )
  (decode_layers): ModuleDict(
    (latent_noise): GaussianNoise()
    (conv0): ConvTranspose1d(6, 4, kernel_size=(3,), stride=(1,))
    (softmax): Softmax(dim=1)
  )
)
Loading data...
Split training and validation sets...
Create data loaders...
Training for 2 epochs
Using device:
cuda
Saving model to outputs/src/ae/experiment/TEST_get_as_onehotchr22_excerpt_4mAutoencoder3x6d0.0n0.2l0.0_4at0.1_2-4986.pth
Runtime:  109.17236171598779
Config values:
{'name': 'TEST_get_as_onehot', 'model': 'Autoencoder', 'kernel_len': 3, 'latent_len': 6, 'seq_len': 40, 'seq_per_batch': 20, 'input_path': 'data/ref_genome/chr22_excerpt_4m.fa', 'split_prop': 0.05, 'epochs': 2, 'learn_rate': 0.1, 'input_dropout_freq': 0.0, 'latent_noise_std': 0.2, 'save_model': True, 'disable_eval': True, 'neighbour_loss_prop': 0.0, 'load_prev_model_state': None, 'hidden_len': 1, 'pool_size': 1, 'n_conv_and_pool': 1, 'n_conv_before_pool': 1, 'n_linear': 1, 'use_cuda_if_available': True, 'hidden_dropout_freq': 0.1, 'fixed_random_seed': True, 'n_dataloader_workers': 4, 'checkpoint_interval': 10000, 'output_len': 919, 'TEST_use_old_dataset': False, 'TEST_get_as_onehot': True, 'TEST_get_label': False}
reading sequence from file...
Model specification:
Autoencoder(
  (loss_fn): NeighbourDistanceLoss(
    (bce_loss): BCELoss()
    (mse_loss): MSELoss()
  )
  (encode_layers): ModuleDict(
    (input_dropout): SeqDropout(
      (dropout): Dropout2d(p=0.0, inplace=False)
    )
    (conv0): Conv1d(4, 6, kernel_size=(3,), stride=(1,))
    (relu0): ReLU()
  )
  (decode_layers): ModuleDict(
    (latent_noise): GaussianNoise()
    (conv0): ConvTranspose1d(6, 4, kernel_size=(3,), stride=(1,))
    (softmax): Softmax(dim=1)
  )
)
Loading data...
Split training and validation sets...
Create data loaders...
Training for 2 epochs
Using device:
cuda
Saving model to outputs/src/ae/experiment/TEST_get_as_onehotchr22_excerpt_4mAutoencoder3x6d0.0n0.2l0.0_4at0.1_2-4986.pth
Config values:
{'name': 'TEST_get_as_onehot', 'model': 'Autoencoder', 'kernel_len': 3, 'latent_len': 6, 'seq_len': 40, 'seq_per_batch': 20, 'input_path': 'data/ref_genome/chr22_excerpt_4m.fa', 'split_prop': 0.05, 'epochs': 2, 'learn_rate': 0.1, 'input_dropout_freq': 0.0, 'latent_noise_std': 0.2, 'save_model': True, 'disable_eval': True, 'neighbour_loss_prop': 0.0, 'load_prev_model_state': None, 'hidden_len': 1, 'pool_size': 1, 'n_conv_and_pool': 1, 'n_conv_before_pool': 1, 'n_linear': 1, 'use_cuda_if_available': True, 'hidden_dropout_freq': 0.1, 'fixed_random_seed': True, 'n_dataloader_workers': 4, 'checkpoint_interval': 10000, 'output_len': 919, 'TEST_use_old_dataset': False, 'TEST_get_as_onehot': True, 'TEST_get_label': False}
reading sequence from file...
Model specification:
Autoencoder(
  (loss_fn): NeighbourDistanceLoss(
    (bce_loss): BCELoss()
    (mse_loss): MSELoss()
  )
  (encode_layers): ModuleDict(
    (input_dropout): SeqDropout(
      (dropout): Dropout2d(p=0.0, inplace=False)
    )
    (conv0): Conv1d(4, 6, kernel_size=(3,), stride=(1,))
    (relu0): ReLU()
  )
  (decode_layers): ModuleDict(
    (latent_noise): GaussianNoise()
    (conv0): ConvTranspose1d(6, 4, kernel_size=(3,), stride=(1,))
    (softmax): Softmax(dim=1)
  )
)
Loading data...
Split training and validation sets...
Create data loaders...
Training for 2 epochs
Using device:
cuda
Saving model to outputs/src/ae/experiment/TEST_get_as_onehotchr22_excerpt_4mAutoencoder3x6d0.0n0.2l0.0_4at0.1_2-4986.pth
Config values:
{'name': 'TEST_get_as_onehot', 'model': 'Autoencoder', 'kernel_len': 3, 'latent_len': 6, 'seq_len': 40, 'seq_per_batch': 20, 'input_path': 'data/ref_genome/chr22_excerpt_4m.fa', 'split_prop': 0.05, 'epochs': 2, 'learn_rate': 0.1, 'input_dropout_freq': 0.0, 'latent_noise_std': 0.2, 'save_model': True, 'disable_eval': True, 'neighbour_loss_prop': 0.0, 'load_prev_model_state': None, 'hidden_len': 1, 'pool_size': 1, 'n_conv_and_pool': 1, 'n_conv_before_pool': 1, 'n_linear': 1, 'use_cuda_if_available': True, 'hidden_dropout_freq': 0.1, 'fixed_random_seed': True, 'n_dataloader_workers': 4, 'checkpoint_interval': 10000, 'output_len': 919, 'TEST_use_old_dataset': False, 'TEST_get_as_onehot': True, 'TEST_get_label': False}
reading sequence from file...
Model specification:
Autoencoder(
  (loss_fn): NeighbourDistanceLoss(
    (bce_loss): BCELoss()
    (mse_loss): MSELoss()
  )
  (encode_layers): ModuleDict(
    (input_dropout): SeqDropout(
      (dropout): Dropout2d(p=0.0, inplace=False)
    )
    (conv0): Conv1d(4, 6, kernel_size=(3,), stride=(1,))
    (relu0): ReLU()
  )
  (decode_layers): ModuleDict(
    (latent_noise): GaussianNoise()
    (conv0): ConvTranspose1d(6, 4, kernel_size=(3,), stride=(1,))
    (softmax): Softmax(dim=1)
  )
)
Loading data...
Split training and validation sets...
Create data loaders...
Training for 2 epochs
Using device:
cuda
Saving model to outputs/src/ae/experiment/TEST_get_as_onehotchr22_excerpt_4mAutoencoder3x6d0.0n0.2l0.0_4at0.1_2-4986.pth
Config values:
{'name': 'TEST_get_as_onehot', 'model': 'Autoencoder', 'kernel_len': 3, 'latent_len': 6, 'seq_len': 40, 'seq_per_batch': 20, 'input_path': 'data/ref_genome/chr22_excerpt_4m.fa', 'split_prop': 0.05, 'epochs': 2, 'learn_rate': 0.1, 'input_dropout_freq': 0.0, 'latent_noise_std': 0.2, 'save_model': True, 'disable_eval': True, 'neighbour_loss_prop': 0.0, 'load_prev_model_state': None, 'hidden_len': 1, 'pool_size': 1, 'n_conv_and_pool': 1, 'n_conv_before_pool': 1, 'n_linear': 1, 'use_cuda_if_available': True, 'hidden_dropout_freq': 0.1, 'fixed_random_seed': True, 'n_dataloader_workers': 4, 'checkpoint_interval': 10000, 'output_len': 919, 'TEST_use_old_dataset': False, 'TEST_get_as_onehot': True, 'TEST_get_label': False}
reading sequence from file...
Model specification:
Autoencoder(
  (loss_fn): NeighbourDistanceLoss(
    (bce_loss): BCELoss()
    (mse_loss): MSELoss()
  )
  (encode_layers): ModuleDict(
    (input_dropout): SeqDropout(
      (dropout): Dropout2d(p=0.0, inplace=False)
    )
    (conv0): Conv1d(4, 6, kernel_size=(3,), stride=(1,))
    (relu0): ReLU()
  )
  (decode_layers): ModuleDict(
    (latent_noise): GaussianNoise()
    (conv0): ConvTranspose1d(6, 4, kernel_size=(3,), stride=(1,))
    (softmax): Softmax(dim=1)
  )
)
Loading data...
Split training and validation sets...
Create data loaders...
Training for 2 epochs
Using device:
cuda
Saving model to outputs/src/ae/experiment/TEST_get_as_onehotchr22_excerpt_4mAutoencoder3x6d0.0n0.2l0.0_4at0.1_2-4986.pth
Config values:
{'name': 'TEST_get_as_onehot', 'model': 'Autoencoder', 'kernel_len': 3, 'latent_len': 6, 'seq_len': 40, 'seq_per_batch': 20, 'input_path': 'data/ref_genome/chr22_excerpt_4m.fa', 'split_prop': 0.05, 'epochs': 2, 'learn_rate': 0.1, 'input_dropout_freq': 0.0, 'latent_noise_std': 0.2, 'save_model': True, 'disable_eval': True, 'neighbour_loss_prop': 0.0, 'load_prev_model_state': None, 'hidden_len': 1, 'pool_size': 1, 'n_conv_and_pool': 1, 'n_conv_before_pool': 1, 'n_linear': 1, 'use_cuda_if_available': True, 'hidden_dropout_freq': 0.1, 'fixed_random_seed': True, 'n_dataloader_workers': 4, 'checkpoint_interval': 10000, 'output_len': 919, 'TEST_use_old_dataset': False, 'TEST_get_as_onehot': True, 'TEST_get_label': False}
reading sequence from file...
Model specification:
Autoencoder(
  (loss_fn): NeighbourDistanceLoss(
    (bce_loss): BCELoss()
    (mse_loss): MSELoss()
  )
  (encode_layers): ModuleDict(
    (input_dropout): SeqDropout(
      (dropout): Dropout2d(p=0.0, inplace=False)
    )
    (conv0): Conv1d(4, 6, kernel_size=(3,), stride=(1,))
    (relu0): ReLU()
  )
  (decode_layers): ModuleDict(
    (latent_noise): GaussianNoise()
    (conv0): ConvTranspose1d(6, 4, kernel_size=(3,), stride=(1,))
    (softmax): Softmax(dim=1)
  )
)
Loading data...
Split training and validation sets...
Create data loaders...
Training for 2 epochs
Using device:
cuda
Saving model to outputs/src/ae/experiment/TEST_get_as_onehotchr22_excerpt_4mAutoencoder3x6d0.0n0.2l0.0_4at0.1_2-4986.pth
Runtime:  98.93816355394665
Config values:
{'name': 'TEST_get_as_onehot_multilayer', 'model': 'MultilayerAutoencoder', 'kernel_len': 9, 'latent_len': 200, 'seq_len': 64, 'seq_per_batch': 100, 'input_path': 'data/ref_genome/chr22_excerpt_4m.fa', 'split_prop': 0.05, 'epochs': 1, 'learn_rate': 0.1, 'input_dropout_freq': 0.05, 'latent_noise_std': 0.2, 'save_model': True, 'disable_eval': True, 'neighbour_loss_prop': 0.0, 'load_prev_model_state': None, 'hidden_len': 24, 'pool_size': 4, 'n_conv_and_pool': 2, 'n_conv_before_pool': 2, 'n_linear': 2, 'use_cuda_if_available': True, 'hidden_dropout_freq': 0.05, 'fixed_random_seed': True, 'n_dataloader_workers': 4, 'checkpoint_interval': 10000, 'output_len': 919, 'TEST_use_old_dataset': False, 'TEST_get_as_onehot': False, 'TEST_get_label': False}
reading sequence from file...
Model specification:
Autoencoder(
  (loss_fn): NeighbourDistanceLoss(
    (bce_loss): BCELoss()
    (mse_loss): MSELoss()
  )
  (encode_layers): ModuleDict(
    (input_dropout): SeqDropout(
      (dropout): Dropout2d(p=0.05, inplace=False)
    )
    (conv0): Conv1d(4, 200, kernel_size=(9,), stride=(1,))
    (relu0): ReLU()
  )
  (decode_layers): ModuleDict(
    (latent_noise): GaussianNoise()
    (conv0): ConvTranspose1d(200, 4, kernel_size=(9,), stride=(1,))
    (softmax): Softmax(dim=1)
  )
)
Loading data...
Split training and validation sets...
Create data loaders...
Training for 1 epochs
Using device:
cuda
Saving model to outputs/src/ae/experiment/TEST_get_as_onehot_multilayerchr22_excerpt_4mMultilayerAutoencoder9x200d0.05n0.2l0.0_2at0.1_1-677.pth
Config values:
{'name': 'TEST_get_as_onehot_multilayer', 'model': 'MultilayerAutoencoder', 'kernel_len': 9, 'latent_len': 200, 'seq_len': 64, 'seq_per_batch': 100, 'input_path': 'data/ref_genome/chr22_excerpt_4m.fa', 'split_prop': 0.05, 'epochs': 1, 'learn_rate': 0.1, 'input_dropout_freq': 0.05, 'latent_noise_std': 0.2, 'save_model': True, 'disable_eval': True, 'neighbour_loss_prop': 0.0, 'load_prev_model_state': None, 'hidden_len': 24, 'pool_size': 4, 'n_conv_and_pool': 2, 'n_conv_before_pool': 2, 'n_linear': 2, 'use_cuda_if_available': True, 'hidden_dropout_freq': 0.05, 'fixed_random_seed': True, 'n_dataloader_workers': 4, 'checkpoint_interval': 10000, 'output_len': 919, 'TEST_use_old_dataset': False, 'TEST_get_as_onehot': False, 'TEST_get_label': False}
reading sequence from file...
Model specification:
Autoencoder(
  (loss_fn): NeighbourDistanceLoss(
    (bce_loss): BCELoss()
    (mse_loss): MSELoss()
  )
  (encode_layers): ModuleDict(
    (input_dropout): SeqDropout(
      (dropout): Dropout2d(p=0.05, inplace=False)
    )
    (conv0): Conv1d(4, 200, kernel_size=(9,), stride=(1,))
    (relu0): ReLU()
  )
  (decode_layers): ModuleDict(
    (latent_noise): GaussianNoise()
    (conv0): ConvTranspose1d(200, 4, kernel_size=(9,), stride=(1,))
    (softmax): Softmax(dim=1)
  )
)
Loading data...
Split training and validation sets...
Create data loaders...
Training for 1 epochs
Using device:
cuda
Saving model to outputs/src/ae/experiment/TEST_get_as_onehot_multilayerchr22_excerpt_4mMultilayerAutoencoder9x200d0.05n0.2l0.0_2at0.1_1-677.pth
Config values:
{'name': 'TEST_get_as_onehot_multilayer', 'model': 'MultilayerAutoencoder', 'kernel_len': 9, 'latent_len': 200, 'seq_len': 64, 'seq_per_batch': 100, 'input_path': 'data/ref_genome/chr22_excerpt_4m.fa', 'split_prop': 0.05, 'epochs': 1, 'learn_rate': 0.1, 'input_dropout_freq': 0.05, 'latent_noise_std': 0.2, 'save_model': True, 'disable_eval': True, 'neighbour_loss_prop': 0.0, 'load_prev_model_state': None, 'hidden_len': 24, 'pool_size': 4, 'n_conv_and_pool': 2, 'n_conv_before_pool': 2, 'n_linear': 2, 'use_cuda_if_available': True, 'hidden_dropout_freq': 0.05, 'fixed_random_seed': True, 'n_dataloader_workers': 4, 'checkpoint_interval': 10000, 'output_len': 919, 'TEST_use_old_dataset': False, 'TEST_get_as_onehot': False, 'TEST_get_label': False}
reading sequence from file...
Model specification:
Autoencoder(
  (loss_fn): NeighbourDistanceLoss(
    (bce_loss): BCELoss()
    (mse_loss): MSELoss()
  )
  (encode_layers): ModuleDict(
    (input_dropout): SeqDropout(
      (dropout): Dropout2d(p=0.05, inplace=False)
    )
    (conv0): Conv1d(4, 200, kernel_size=(9,), stride=(1,))
    (relu0): ReLU()
  )
  (decode_layers): ModuleDict(
    (latent_noise): GaussianNoise()
    (conv0): ConvTranspose1d(200, 4, kernel_size=(9,), stride=(1,))
    (softmax): Softmax(dim=1)
  )
)
Loading data...
Split training and validation sets...
Create data loaders...
Training for 1 epochs
Using device:
cuda
Saving model to outputs/src/ae/experiment/TEST_get_as_onehot_multilayerchr22_excerpt_4mMultilayerAutoencoder9x200d0.05n0.2l0.0_2at0.1_1-677.pth
Config values:
{'name': 'TEST_get_as_onehot_multilayer', 'model': 'MultilayerAutoencoder', 'kernel_len': 9, 'latent_len': 200, 'seq_len': 64, 'seq_per_batch': 100, 'input_path': 'data/ref_genome/chr22_excerpt_4m.fa', 'split_prop': 0.05, 'epochs': 1, 'learn_rate': 0.1, 'input_dropout_freq': 0.05, 'latent_noise_std': 0.2, 'save_model': True, 'disable_eval': True, 'neighbour_loss_prop': 0.0, 'load_prev_model_state': None, 'hidden_len': 24, 'pool_size': 4, 'n_conv_and_pool': 2, 'n_conv_before_pool': 2, 'n_linear': 2, 'use_cuda_if_available': True, 'hidden_dropout_freq': 0.05, 'fixed_random_seed': True, 'n_dataloader_workers': 4, 'checkpoint_interval': 10000, 'output_len': 919, 'TEST_use_old_dataset': False, 'TEST_get_as_onehot': False, 'TEST_get_label': False}
reading sequence from file...
Model specification:
Autoencoder(
  (loss_fn): NeighbourDistanceLoss(
    (bce_loss): BCELoss()
    (mse_loss): MSELoss()
  )
  (encode_layers): ModuleDict(
    (input_dropout): SeqDropout(
      (dropout): Dropout2d(p=0.05, inplace=False)
    )
    (conv0): Conv1d(4, 200, kernel_size=(9,), stride=(1,))
    (relu0): ReLU()
  )
  (decode_layers): ModuleDict(
    (latent_noise): GaussianNoise()
    (conv0): ConvTranspose1d(200, 4, kernel_size=(9,), stride=(1,))
    (softmax): Softmax(dim=1)
  )
)
Loading data...
Split training and validation sets...
Create data loaders...
Training for 1 epochs
Using device:
cuda
Saving model to outputs/src/ae/experiment/TEST_get_as_onehot_multilayerchr22_excerpt_4mMultilayerAutoencoder9x200d0.05n0.2l0.0_2at0.1_1-677.pth
Config values:
{'name': 'TEST_get_as_onehot_multilayer', 'model': 'MultilayerAutoencoder', 'kernel_len': 9, 'latent_len': 200, 'seq_len': 64, 'seq_per_batch': 100, 'input_path': 'data/ref_genome/chr22_excerpt_4m.fa', 'split_prop': 0.05, 'epochs': 1, 'learn_rate': 0.1, 'input_dropout_freq': 0.05, 'latent_noise_std': 0.2, 'save_model': True, 'disable_eval': True, 'neighbour_loss_prop': 0.0, 'load_prev_model_state': None, 'hidden_len': 24, 'pool_size': 4, 'n_conv_and_pool': 2, 'n_conv_before_pool': 2, 'n_linear': 2, 'use_cuda_if_available': True, 'hidden_dropout_freq': 0.05, 'fixed_random_seed': True, 'n_dataloader_workers': 4, 'checkpoint_interval': 10000, 'output_len': 919, 'TEST_use_old_dataset': False, 'TEST_get_as_onehot': False, 'TEST_get_label': False}
reading sequence from file...
Model specification:
Autoencoder(
  (loss_fn): NeighbourDistanceLoss(
    (bce_loss): BCELoss()
    (mse_loss): MSELoss()
  )
  (encode_layers): ModuleDict(
    (input_dropout): SeqDropout(
      (dropout): Dropout2d(p=0.05, inplace=False)
    )
    (conv0): Conv1d(4, 200, kernel_size=(9,), stride=(1,))
    (relu0): ReLU()
  )
  (decode_layers): ModuleDict(
    (latent_noise): GaussianNoise()
    (conv0): ConvTranspose1d(200, 4, kernel_size=(9,), stride=(1,))
    (softmax): Softmax(dim=1)
  )
)
Loading data...
Split training and validation sets...
Create data loaders...
Training for 1 epochs
Using device:
cuda
Saving model to outputs/src/ae/experiment/TEST_get_as_onehot_multilayerchr22_excerpt_4mMultilayerAutoencoder9x200d0.05n0.2l0.0_2at0.1_1-677.pth
Runtime:  16.25778549996903
Config values:
{'name': 'TEST_get_as_onehot_multilayer', 'model': 'MultilayerAutoencoder', 'kernel_len': 9, 'latent_len': 200, 'seq_len': 64, 'seq_per_batch': 100, 'input_path': 'data/ref_genome/chr22_excerpt_4m.fa', 'split_prop': 0.05, 'epochs': 1, 'learn_rate': 0.1, 'input_dropout_freq': 0.05, 'latent_noise_std': 0.2, 'save_model': True, 'disable_eval': True, 'neighbour_loss_prop': 0.0, 'load_prev_model_state': None, 'hidden_len': 24, 'pool_size': 4, 'n_conv_and_pool': 2, 'n_conv_before_pool': 2, 'n_linear': 2, 'use_cuda_if_available': True, 'hidden_dropout_freq': 0.05, 'fixed_random_seed': True, 'n_dataloader_workers': 4, 'checkpoint_interval': 10000, 'output_len': 919, 'TEST_use_old_dataset': False, 'TEST_get_as_onehot': True, 'TEST_get_label': False}
reading sequence from file...
Model specification:
Autoencoder(
  (loss_fn): NeighbourDistanceLoss(
    (bce_loss): BCELoss()
    (mse_loss): MSELoss()
  )
  (encode_layers): ModuleDict(
    (input_dropout): SeqDropout(
      (dropout): Dropout2d(p=0.05, inplace=False)
    )
    (conv0): Conv1d(4, 200, kernel_size=(9,), stride=(1,))
    (relu0): ReLU()
  )
  (decode_layers): ModuleDict(
    (latent_noise): GaussianNoise()
    (conv0): ConvTranspose1d(200, 4, kernel_size=(9,), stride=(1,))
    (softmax): Softmax(dim=1)
  )
)
Loading data...
Split training and validation sets...
Create data loaders...
Training for 1 epochs
Using device:
cuda
Saving model to outputs/src/ae/experiment/TEST_get_as_onehot_multilayerchr22_excerpt_4mMultilayerAutoencoder9x200d0.05n0.2l0.0_2at0.1_1-677.pth
Config values:
{'name': 'TEST_get_as_onehot_multilayer', 'model': 'MultilayerAutoencoder', 'kernel_len': 9, 'latent_len': 200, 'seq_len': 64, 'seq_per_batch': 100, 'input_path': 'data/ref_genome/chr22_excerpt_4m.fa', 'split_prop': 0.05, 'epochs': 1, 'learn_rate': 0.1, 'input_dropout_freq': 0.05, 'latent_noise_std': 0.2, 'save_model': True, 'disable_eval': True, 'neighbour_loss_prop': 0.0, 'load_prev_model_state': None, 'hidden_len': 24, 'pool_size': 4, 'n_conv_and_pool': 2, 'n_conv_before_pool': 2, 'n_linear': 2, 'use_cuda_if_available': True, 'hidden_dropout_freq': 0.05, 'fixed_random_seed': True, 'n_dataloader_workers': 4, 'checkpoint_interval': 10000, 'output_len': 919, 'TEST_use_old_dataset': False, 'TEST_get_as_onehot': True, 'TEST_get_label': False}
reading sequence from file...
Model specification:
Autoencoder(
  (loss_fn): NeighbourDistanceLoss(
    (bce_loss): BCELoss()
    (mse_loss): MSELoss()
  )
  (encode_layers): ModuleDict(
    (input_dropout): SeqDropout(
      (dropout): Dropout2d(p=0.05, inplace=False)
    )
    (conv0): Conv1d(4, 200, kernel_size=(9,), stride=(1,))
    (relu0): ReLU()
  )
  (decode_layers): ModuleDict(
    (latent_noise): GaussianNoise()
    (conv0): ConvTranspose1d(200, 4, kernel_size=(9,), stride=(1,))
    (softmax): Softmax(dim=1)
  )
)
Loading data...
Split training and validation sets...
Create data loaders...
Training for 1 epochs
Using device:
cuda
Saving model to outputs/src/ae/experiment/TEST_get_as_onehot_multilayerchr22_excerpt_4mMultilayerAutoencoder9x200d0.05n0.2l0.0_2at0.1_1-677.pth
Config values:
{'name': 'TEST_get_as_onehot_multilayer', 'model': 'MultilayerAutoencoder', 'kernel_len': 9, 'latent_len': 200, 'seq_len': 64, 'seq_per_batch': 100, 'input_path': 'data/ref_genome/chr22_excerpt_4m.fa', 'split_prop': 0.05, 'epochs': 1, 'learn_rate': 0.1, 'input_dropout_freq': 0.05, 'latent_noise_std': 0.2, 'save_model': True, 'disable_eval': True, 'neighbour_loss_prop': 0.0, 'load_prev_model_state': None, 'hidden_len': 24, 'pool_size': 4, 'n_conv_and_pool': 2, 'n_conv_before_pool': 2, 'n_linear': 2, 'use_cuda_if_available': True, 'hidden_dropout_freq': 0.05, 'fixed_random_seed': True, 'n_dataloader_workers': 4, 'checkpoint_interval': 10000, 'output_len': 919, 'TEST_use_old_dataset': False, 'TEST_get_as_onehot': True, 'TEST_get_label': False}
reading sequence from file...
Model specification:
Autoencoder(
  (loss_fn): NeighbourDistanceLoss(
    (bce_loss): BCELoss()
    (mse_loss): MSELoss()
  )
  (encode_layers): ModuleDict(
    (input_dropout): SeqDropout(
      (dropout): Dropout2d(p=0.05, inplace=False)
    )
    (conv0): Conv1d(4, 200, kernel_size=(9,), stride=(1,))
    (relu0): ReLU()
  )
  (decode_layers): ModuleDict(
    (latent_noise): GaussianNoise()
    (conv0): ConvTranspose1d(200, 4, kernel_size=(9,), stride=(1,))
    (softmax): Softmax(dim=1)
  )
)
Loading data...
Split training and validation sets...
Create data loaders...
Training for 1 epochs
Using device:
cuda
Saving model to outputs/src/ae/experiment/TEST_get_as_onehot_multilayerchr22_excerpt_4mMultilayerAutoencoder9x200d0.05n0.2l0.0_2at0.1_1-677.pth
Config values:
{'name': 'TEST_get_as_onehot_multilayer', 'model': 'MultilayerAutoencoder', 'kernel_len': 9, 'latent_len': 200, 'seq_len': 64, 'seq_per_batch': 100, 'input_path': 'data/ref_genome/chr22_excerpt_4m.fa', 'split_prop': 0.05, 'epochs': 1, 'learn_rate': 0.1, 'input_dropout_freq': 0.05, 'latent_noise_std': 0.2, 'save_model': True, 'disable_eval': True, 'neighbour_loss_prop': 0.0, 'load_prev_model_state': None, 'hidden_len': 24, 'pool_size': 4, 'n_conv_and_pool': 2, 'n_conv_before_pool': 2, 'n_linear': 2, 'use_cuda_if_available': True, 'hidden_dropout_freq': 0.05, 'fixed_random_seed': True, 'n_dataloader_workers': 4, 'checkpoint_interval': 10000, 'output_len': 919, 'TEST_use_old_dataset': False, 'TEST_get_as_onehot': True, 'TEST_get_label': False}
reading sequence from file...
Model specification:
Autoencoder(
  (loss_fn): NeighbourDistanceLoss(
    (bce_loss): BCELoss()
    (mse_loss): MSELoss()
  )
  (encode_layers): ModuleDict(
    (input_dropout): SeqDropout(
      (dropout): Dropout2d(p=0.05, inplace=False)
    )
    (conv0): Conv1d(4, 200, kernel_size=(9,), stride=(1,))
    (relu0): ReLU()
  )
  (decode_layers): ModuleDict(
    (latent_noise): GaussianNoise()
    (conv0): ConvTranspose1d(200, 4, kernel_size=(9,), stride=(1,))
    (softmax): Softmax(dim=1)
  )
)
Loading data...
Split training and validation sets...
Create data loaders...
Training for 1 epochs
Using device:
cuda
Saving model to outputs/src/ae/experiment/TEST_get_as_onehot_multilayerchr22_excerpt_4mMultilayerAutoencoder9x200d0.05n0.2l0.0_2at0.1_1-677.pth
Config values:
{'name': 'TEST_get_as_onehot_multilayer', 'model': 'MultilayerAutoencoder', 'kernel_len': 9, 'latent_len': 200, 'seq_len': 64, 'seq_per_batch': 100, 'input_path': 'data/ref_genome/chr22_excerpt_4m.fa', 'split_prop': 0.05, 'epochs': 1, 'learn_rate': 0.1, 'input_dropout_freq': 0.05, 'latent_noise_std': 0.2, 'save_model': True, 'disable_eval': True, 'neighbour_loss_prop': 0.0, 'load_prev_model_state': None, 'hidden_len': 24, 'pool_size': 4, 'n_conv_and_pool': 2, 'n_conv_before_pool': 2, 'n_linear': 2, 'use_cuda_if_available': True, 'hidden_dropout_freq': 0.05, 'fixed_random_seed': True, 'n_dataloader_workers': 4, 'checkpoint_interval': 10000, 'output_len': 919, 'TEST_use_old_dataset': False, 'TEST_get_as_onehot': True, 'TEST_get_label': False}
reading sequence from file...
Model specification:
Autoencoder(
  (loss_fn): NeighbourDistanceLoss(
    (bce_loss): BCELoss()
    (mse_loss): MSELoss()
  )
  (encode_layers): ModuleDict(
    (input_dropout): SeqDropout(
      (dropout): Dropout2d(p=0.05, inplace=False)
    )
    (conv0): Conv1d(4, 200, kernel_size=(9,), stride=(1,))
    (relu0): ReLU()
  )
  (decode_layers): ModuleDict(
    (latent_noise): GaussianNoise()
    (conv0): ConvTranspose1d(200, 4, kernel_size=(9,), stride=(1,))
    (softmax): Softmax(dim=1)
  )
)
Loading data...
Split training and validation sets...
Create data loaders...
Training for 1 epochs
Using device:
cuda
Saving model to outputs/src/ae/experiment/TEST_get_as_onehot_multilayerchr22_excerpt_4mMultilayerAutoencoder9x200d0.05n0.2l0.0_2at0.1_1-677.pth
Runtime:  16.767349421977997

real	4m2.496s
user	11m19.783s
sys	0m37.833s
